# **Week 1: Foundations of RL & Multi-Armed Bandits**

In this week, we will explore core and fundamental concepts of Reinforcement Learning and explore the Multi-Armed Bandit (MAB) problem. You will learn about the trade-off between exploration and exploitation and implement some strategies to solve it.

This week has 1 assignment:
* **Multi-Armed Bandit Assignment**: Fill the TODOs in `assignment.ipynb` to implement epsilon-Greedy, UCB, and Thompson Sampling algorithms.

---

### **References**

#### **Reading Materials**
* **[Reinforcement Learning: An Introduction (Sutton & Barto)](https://drive.google.com/file/d/1ngy8aAPBxWi3oBpRM2jv5CPXDObVc7N-/view?usp=drive_link)**:
    * **Chapter 1**: Introduction to the RL framework.
    * **Chapter 2**: Detailed study of the Multi-Armed Bandit problem.

#### **Video Tutorials**
* **[Introduction to Reinforcement Learning](https://www.youtube.com/watch?v=JgvyzIkgxF0)**: An overview of RL
* **[The epsilon-Greedy Strategy](https://youtu.be/EjYEsbg95x0?feature=shared)**
* **[Upper Confidence Bound (UCB)](https://youtu.be/s6UHInwoqb0?feature=shared)**: Learning to explore based on the uncertainty or variance in the estimate of an action's value.
* **[Thompson Sampling](https://youtu.be/GVQUGNv33LY?feature=shared)**: A probabilistic approach to the exploration-exploitation trade-offs
