# **Week 2: Markov Decision Processes & Value Functions**

In this week, we move from stateless decision-making (Multi-Armed Bandits)
to sequential decision-making using **Markov Decision Processes (MDPs).**

Topics covered:
- Markov Decision Processes (states, actions, transitions, rewards)
- Discount factor and return
- Value functions and Bellman optimality equation
- Value Iteration algorithm

Assignment:
Implement Value Iteration for a small finite MDP and extract the optimal policy.

Note: The optimal policy favors long-term discounted rewards over immediate terminal rewards.
